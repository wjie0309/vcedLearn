## VCED 实现

VCED 的核心实现逻辑是通过 CLIP 模型实现的. CLIP 模型如下所示:


- 通过 Text Encoder 将文字内容 Embedding, 转化为高维向量.
- 通过 Image Encoder 将视频内容进行关键帧筛选, 转化为多张图片数据进行 Embedding.
- 跨模态模型的目标是: 将文本的向量和关键帧图片的向量映射到同一个高维空间下, 并使得文本描述与视频内容相符合的向量距离尽可能近.
- 最后输入一段文本后就可以用相同的方法将生成的向量与存储的向量进行比对，判断哪些向量之间的距离比较近，得到一个相似性分数，即可以找到离文本描述最相似的关键帧，再对原视频进行定位，最终找到相似的视频片段.

为了实现以上几个步骤，在本项目中引入了以下组件：

-   为了解决如何对视频进行关键帧提取的问题，我们使用到了 ffmpeg，对应的实现方法在 [videoLoader](https://github.com/datawhalechina/vced/blob/709de9a0a0ce6a0b534c243c5bb58e00a08c6379/code/service/videoLoader/video_loader.py) 中
    
-   为了解决如何将文本与图像转换为向量的问题，我们使用到了 jina 的 DocArray，对应处理文本的方法在 [customClipText](https://github.com/datawhalechina/vced/blob/709de9a0a0ce6a0b534c243c5bb58e00a08c6379/code/service/customClipText/clip_text.py) 中，对应处理图像的方法在 [customClipImage](https://github.com/datawhalechina/vced/blob/709de9a0a0ce6a0b534c243c5bb58e00a08c6379/code/service/customClipImage/clip_image.py) 中
    
-   为了解决如何将生成的向量数据存储以及检索的问题，我们使用到了 jina 自带的向量搜索方法，对应的实现方法在 [customIndexer](https://github.com/datawhalechina/vced/blob/709de9a0a0ce6a0b534c243c5bb58e00a08c6379/code/service/customIndexer/executor.py) 中
    
-   为了解决前端显示的问题，我们使用到了 [Streamlit](https://streamlit.io/) 框架实现前端效果，对应的实现方法在 [web/app.py](https://github.com/datawhalechina/vced/blob/709de9a0a0ce6a0b534c243c5bb58e00a08c6379/code/web/app.py) 中

## CLIP 模型详解

CLIP模型将原有的图像标签替换为图像的文本描述信息，来监督视觉任务的训练.

对 CLIP 模型进行了解, 可以先分别从图像处理和语言处理两个部分开始了解.

### 模型前置原理

模型最前端的神经网络层倾向于提取一些普遍的、共有的视觉特征，如纹理、边缘等信息。越往后则越倾向于任务相关的特征。涉及计算机视觉图像分类的模型，在特征提取功能上，更多的依赖模型的前端的神经层，而将特征映射到标签的功能则更多的依赖于模型末端的神经层.

当我们进行图片分类任务的时候, 监督学习的做法常常是给不同情况的数据打上标签, 进行分类任务. 但是我们也可以通过对比学习的方式实现分类, 即在训练过程中, 把同一类别的数据向量处理为相互距离尽可能接近, 不属于同一类别的向量尽可能拉远.

映照这种思路, 如果我们可以把语义学习和图像训练的向量数据放在同一个向量空间, 进行对比学习, 那么我们可以在不提前标注的情况下使得多个模态建立起联系.

### Zero-shot Learning

Zero-shot learning, 指的是在没有当前类别的训练样本的情况下, 能够让模型学习到一种映射方法, 将这种类别的样本映射到原有的向量空间, 再通过向量空间中不同样本之间的距离判断这个样本可能会属于哪个类别.

Clip(Contrastive Language-Image Pretraining) 将语言信息和图像信息联合训练，实现了在下游任务上 zero-shot learning.

CLIP 实现的内容可以描述为: 将关键帧图片的高维向量作为一维, 语义的高维向量作为另一个维度, 二维矩阵中每一个元素的定义是对应行列的数据的相似度. 而我们的优化目标就是使得这个二维矩阵的对角线上元素尽可能大, 其他元素尽可能小 (增大相似向量的相关性, 减低不同向量的相关性).

## 其他多模态模型

### Diffusion

Diffusion 模型是最近大火的图文生成领域多模态模型.

Diffusion 的原理同样非常有趣, 如同它的名字一样, diffusion 从扩散的过程中找到灵感.

一个系统的状态从初始的稳定清晰开始, 会随着环境影响(噪声)随着时间逐渐进行演化, 最后达到一种跟之前初始条件完全不同的混沌状态. 这个过程可以在咖啡上很精彩地体现出来. 一杯精美的拉花咖啡, 在时间过程中拉花图案慢慢模糊, 最后完全没有办法辨别出原来的花纹是什么.

这就是在加噪过程中的扩散现象. 而 Diffusion 模型通过学习扩散过程中的噪声数据, 从中找到规律, 然后试图从最后的混沌状态一步步逆向进行加噪过程, 这样就可以呈现出加噪前原本的状态模式.